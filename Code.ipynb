{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GROUP - 11(B)**\n",
        "# **M. Prasanna Teja - [CB.EN.U4AIE21035]**\n",
        "# **P. Sai Ravula - [CB.EN.U4AIE21041]**"
      ],
      "metadata": {
        "id": "oOf7ydmEVZi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data"
      ],
      "metadata": {
        "id": "O_p9nnQYV7Ly"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1PBEmtzvdqe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth',None)\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv(\"final_train.csv\")\n",
        "\n",
        "# Load the testing data\n",
        "test_data = pd.read_csv(\"final_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "ee9zKJnVvxus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005e6dfa-8ff1-401c-d9ef-f358fd0497b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "id": "E-0_D24cC8Kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "4d76d5f4-5975-4b86-c049-6e1f50324575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Random_drop_index                   Datetime      Tweet Id  \\\n",
              "0           0                356  2022-02-13 08:13:35+00:00  1.492774e+18   \n",
              "1           1                524  2022-02-10 13:30:07+00:00  1.491766e+18   \n",
              "2           2                395  2022-02-12 12:18:34+00:00  1.492473e+18   \n",
              "3           3               1074  2018-11-01 15:51:26+00:00  1.058024e+18   \n",
              "4           4               1236  2018-02-17 06:45:00+00:00  9.647525e+17   \n",
              "\n",
              "                                                                                                                                                                                                                                              Text  \\\n",
              "0                                                            ‡∞®‡±á‡∞°‡±Å ‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã ‡∞ú‡±à‡∞≤‡±ç‚Äå‡∞≠‡∞∞‡±ãhttps://t.co/Q6CdSvhoiV#JailBaro #Visakhapatnam #protection #Andhrapradesh #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
              "1                                                                                                                                 BIG NEWS: ‡∞è‡∞™‡±Ä‡∞≤‡±ã ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à ‡∞∏‡±Ä‡∞é‡∞Ç ‡∞ú‡∞ó‡∞®‡±ç ‡∞ï‡±Ä‡∞≤‡∞ï ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å.. ‡∞Ü ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡±Å‡∞Ç‡∞ö‡±á.. #news #dailyhunt https://t.co/mlluIriwKd   \n",
              "2  Rahul Bajaj: ‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§ ‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç‚Äå ‡∞¨‡∞ú‡∞æ‡∞ú‡±ç‚Äå ‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§https://t.co/EzX6LrwJ9r#RahulBajaj #BajajGroup #Industrialist #BajajTwoWheeler #BajajThreeWheeler #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
              "3                                                       ‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å ‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å @Ileana_Official#tollywoodactress #hot #funny #memes #telugu #hyderabad #telengana #birthday #happybirthday #girls #november #IleanaDCruz https://t.co/ZbCgegQo6o   \n",
              "4                                                                                                                                                                                ‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á 6 ‡∞µ ‡∞¶‡∞ø ‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç..!#Funny: üòõ üòõ üòõ https://t.co/uiKN2aPJ26   \n",
              "\n",
              "         Username  Humour  \n",
              "0    hmtvnewslive       0  \n",
              "1       DH_Telugu       0  \n",
              "2    hmtvnewslive       0  \n",
              "3   CoconutComedy       0  \n",
              "4  fbtelugupeople       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-402491a6-54f4-4bd1-a048-19a542bef7d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Random_drop_index</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Tweet Id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Username</th>\n",
              "      <th>Humour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>356</td>\n",
              "      <td>2022-02-13 08:13:35+00:00</td>\n",
              "      <td>1.492774e+18</td>\n",
              "      <td>‡∞®‡±á‡∞°‡±Å ‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã ‡∞ú‡±à‡∞≤‡±ç‚Äå‡∞≠‡∞∞‡±ãhttps://t.co/Q6CdSvhoiV#JailBaro #Visakhapatnam #protection #Andhrapradesh #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews</td>\n",
              "      <td>hmtvnewslive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>524</td>\n",
              "      <td>2022-02-10 13:30:07+00:00</td>\n",
              "      <td>1.491766e+18</td>\n",
              "      <td>BIG NEWS: ‡∞è‡∞™‡±Ä‡∞≤‡±ã ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à ‡∞∏‡±Ä‡∞é‡∞Ç ‡∞ú‡∞ó‡∞®‡±ç ‡∞ï‡±Ä‡∞≤‡∞ï ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å.. ‡∞Ü ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡±Å‡∞Ç‡∞ö‡±á.. #news #dailyhunt https://t.co/mlluIriwKd</td>\n",
              "      <td>DH_Telugu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>395</td>\n",
              "      <td>2022-02-12 12:18:34+00:00</td>\n",
              "      <td>1.492473e+18</td>\n",
              "      <td>Rahul Bajaj: ‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§ ‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç‚Äå ‡∞¨‡∞ú‡∞æ‡∞ú‡±ç‚Äå ‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§https://t.co/EzX6LrwJ9r#RahulBajaj #BajajGroup #Industrialist #BajajTwoWheeler #BajajThreeWheeler #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews</td>\n",
              "      <td>hmtvnewslive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1074</td>\n",
              "      <td>2018-11-01 15:51:26+00:00</td>\n",
              "      <td>1.058024e+18</td>\n",
              "      <td>‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å ‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å @Ileana_Official#tollywoodactress #hot #funny #memes #telugu #hyderabad #telengana #birthday #happybirthday #girls #november #IleanaDCruz https://t.co/ZbCgegQo6o</td>\n",
              "      <td>CoconutComedy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1236</td>\n",
              "      <td>2018-02-17 06:45:00+00:00</td>\n",
              "      <td>9.647525e+17</td>\n",
              "      <td>‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á 6 ‡∞µ ‡∞¶‡∞ø ‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç..!#Funny: üòõ üòõ üòõ https://t.co/uiKN2aPJ26</td>\n",
              "      <td>fbtelugupeople</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-402491a6-54f4-4bd1-a048-19a542bef7d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-402491a6-54f4-4bd1-a048-19a542bef7d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-402491a6-54f4-4bd1-a048-19a542bef7d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7bece19-1832-4311-bc2b-554a888d2775\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7bece19-1832-4311-bc2b-554a888d2775')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7bece19-1832-4311-bc2b-554a888d2775 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 862,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 248,\n        \"min\": 0,\n        \"max\": 861,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          715,\n          605,\n          120\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Random_drop_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 434,\n        \"min\": 0,\n        \"max\": 1646,\n        \"num_unique_values\": 732,\n        \"samples\": [\n          231,\n          1248,\n          728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 859,\n        \"samples\": [\n          \"2020-09-29 08:13:36+00:00\",\n          \"2017-04-23 15:40:20+00:00\",\n          \"2018-12-13 12:34:58+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweet Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.62669303700744e+17,\n        \"min\": 17858252548.0,\n        \"max\": 1.494540625609298e+18,\n        \"num_unique_values\": 860,\n        \"samples\": [\n          1.3080642924790129e+18,\n          1.4695569223742628e+18,\n          1.0731945682778684e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 860,\n        \"samples\": [\n          \"\\u0c24\\u0c2e\\u0c02\\u0c24\\u0c1f \\u0c24\\u0c3e\\u0c2e\\u0c41\\u0c17\\u0c3e \\u0c35\\u0c3f\\u0c35\\u0c3e\\u0c26\\u0c3e\\u0c32\\u0c28\\u0c41 \\u0c24\\u0c32\\u0c15\\u0c46\\u0c24\\u0c4d\\u0c24\\u0c41\\u0c15\\u0c4b\\u0c15\\u0c2a\\u0c4b\\u0c24\\u0c47 \\u0c35\\u0c48\\u0c38\\u0c3f\\u0c2a\\u0c3f \\u0c28\\u0c47\\u0c24\\u0c32\\u0c15\\u0c41 \\u0c28\\u0c3f\\u0c26\\u0c4d\\u0c30 \\u0c2a\\u0c1f\\u0c4d\\u0c1f\\u0c47\\u0c1f\\u0c4d\\u0c32\\u0c41 \\u0c32\\u0c47\\u0c26\\u0c41#indiaheraldcards#SatireView More :https://t.co/v62c93cOgw https://t.co/bZxFJsJxU9\",\n          \"|| \\u0c15\\u0c42\\u0c38\\u0c3f\\u0c02\\u0c24 \\u0c28\\u0c35\\u0c4d\\u0c35\\u0c41 \\u0c15\\u0c4a\\u0c02\\u0c21\\u0c24\\u0c3e \\u0c2c\\u0c30\\u0c41\\u0c35\\u0c41 \\u0c09\\u0c28\\u0c4d\\u0c28 \\u0c2e\\u0c28\\u0c38\\u0c41 \\u0c28\\u0c41\\u0c15\\u0c4b\\u0c1f\\u0c3f \\u0c15\\u0c4d\\u0c37\\u0c23\\u0c3e\\u0c32 \\u0c2a\\u0c3e\\u0c1f\\u0c41 \\u0c06\\u0c28\\u0c02\\u0c26\\u0c02\\u0c17\\u0c3e \\u0c09\\u0c02\\u0c21\\u0c47\\u0c32\\u0c3e \\u0c1a\\u0c47\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c02\\u0c26\\u0c3f..#\\u0c28\\u0c35\\u0c4d\\u0c35\\u0c41 #\\u0c28\\u0c35\\u0c4d\\u0c35\\u0c41\\u0c24\\u0c42 #\\u0c1c\\u0c40\\u0c35\\u0c3f\\u0c02\\u0c1a\\u0c41||#\\u0c36\\u0c4d\\u0c30\\u0c3e\\u0c35\\u0c23\\u0c4d \\u0c28\\u0c3e\\u0c28\\u0c3f@14\\u270d\\ufe0f https://t.co/wXcy6dyiIQ\",\n          \"\\u0c07\\u0c15 \\u0c28\\u0c28\\u0c4d\\u0c28\\u0c41 \\u0c35\\u0c47\\u0c21\\u0c41\\u0c15\\u0c32\\u0c15\\u0c41 \\u0c06\\u0c39\\u0c4d\\u0c35\\u0c3e\\u0c28\\u0c3f\\u0c02\\u0c1a\\u0c30\\u0c47\\u0c2e\\u0c4b...!#katrinakaif, #ranveersingh, #deepikapadukone, #heroine, #zero, #invite, #comments, #funny, #reply, #news, #bollywood, #sharukhkhan, #movie, #pressmeet, #netivaartalu https://t.co/xhHPCMvPFz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Username\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 266,\n        \"samples\": [\n          \"nazir28\",\n          \"LovelySirisha1\",\n          \"Muralichaitu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Humour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head(5)"
      ],
      "metadata": {
        "id": "JgHf08JmFSGq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "dfbed5e0-b2ab-471d-8351-95ca960a60a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Random_drop_index                   Datetime      Tweet Id  \\\n",
              "0           0                273  2022-02-14 14:35:00+00:00  1.493232e+18   \n",
              "1           1               1223  2018-02-24 13:45:24+00:00  9.673950e+17   \n",
              "2           2               1554  2016-05-30 06:40:33+00:00  7.371718e+17   \n",
              "3           3                526  2022-02-10 11:40:06+00:00  1.491739e+18   \n",
              "4           4                405  2022-02-12 10:11:41+00:00  1.492441e+18   \n",
              "\n",
              "                                                                                                                                                                                                                            Text  \\\n",
              "0  ‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç‚Äå‡∞≤‡±ã ‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø ‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á, ‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã ‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á https://t.co/qZpcgskhNu #assembly #poll #campaign #CaptAmarinderSingh #NarendraModi #NDA #YogiAdityanath #Telugu #NEWS #Telangana #AndhraPradesh #NewsUpdates #Newsfile   \n",
              "1                                                                                         ‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞à 22 ‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á ‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å..!‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø..‡∞ï‡∞æ‡∞®‡±Ä.!#Funny: :-P :-P :-P https://t.co/oNQKqUveMa   \n",
              "2                                                                                                                                                              ‡∞Æ‡±Ü‡∞ó‡∞æ ‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø ‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç..!https://t.co/G2BGZgZOr9 #comedy   \n",
              "3                                                                                                                                  ‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å ‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç.. ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ..!! #news #dailyhunt https://t.co/2Srp8tHAz1   \n",
              "4                    ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø ‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞® ‡∞á‡∞∏‡±ç‡∞∞‡±ã ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Åhttps://t.co/00WaqqXcJ7#ISROscientists #Tirumala #PSLVC52 #Rocket #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
              "\n",
              "         Username  Humour  \n",
              "0      NijamToday       0  \n",
              "1  fbtelugupeople       0  \n",
              "2   Kalpanapriyap       0  \n",
              "3       DH_Telugu       0  \n",
              "4    hmtvnewslive       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77d93328-1617-4a3f-b8d4-30662012b467\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Random_drop_index</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Tweet Id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Username</th>\n",
              "      <th>Humour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>273</td>\n",
              "      <td>2022-02-14 14:35:00+00:00</td>\n",
              "      <td>1.493232e+18</td>\n",
              "      <td>‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç‚Äå‡∞≤‡±ã ‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø ‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á, ‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã ‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á https://t.co/qZpcgskhNu #assembly #poll #campaign #CaptAmarinderSingh #NarendraModi #NDA #YogiAdityanath #Telugu #NEWS #Telangana #AndhraPradesh #NewsUpdates #Newsfile</td>\n",
              "      <td>NijamToday</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1223</td>\n",
              "      <td>2018-02-24 13:45:24+00:00</td>\n",
              "      <td>9.673950e+17</td>\n",
              "      <td>‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞à 22 ‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á ‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å..!‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø..‡∞ï‡∞æ‡∞®‡±Ä.!#Funny: :-P :-P :-P https://t.co/oNQKqUveMa</td>\n",
              "      <td>fbtelugupeople</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1554</td>\n",
              "      <td>2016-05-30 06:40:33+00:00</td>\n",
              "      <td>7.371718e+17</td>\n",
              "      <td>‡∞Æ‡±Ü‡∞ó‡∞æ ‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø ‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç..!https://t.co/G2BGZgZOr9 #comedy</td>\n",
              "      <td>Kalpanapriyap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>526</td>\n",
              "      <td>2022-02-10 11:40:06+00:00</td>\n",
              "      <td>1.491739e+18</td>\n",
              "      <td>‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å ‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç.. ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ..!! #news #dailyhunt https://t.co/2Srp8tHAz1</td>\n",
              "      <td>DH_Telugu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>405</td>\n",
              "      <td>2022-02-12 10:11:41+00:00</td>\n",
              "      <td>1.492441e+18</td>\n",
              "      <td>‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø ‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞® ‡∞á‡∞∏‡±ç‡∞∞‡±ã ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Åhttps://t.co/00WaqqXcJ7#ISROscientists #Tirumala #PSLVC52 #Rocket #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews</td>\n",
              "      <td>hmtvnewslive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77d93328-1617-4a3f-b8d4-30662012b467')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77d93328-1617-4a3f-b8d4-30662012b467 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77d93328-1617-4a3f-b8d4-30662012b467');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7cfeb453-4365-401b-8643-8895aafab179\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cfeb453-4365-401b-8643-8895aafab179')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7cfeb453-4365-401b-8643-8895aafab179 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 216,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62,\n        \"min\": 0,\n        \"max\": 215,\n        \"num_unique_values\": 216,\n        \"samples\": [\n          201,\n          213,\n          138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Random_drop_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 439,\n        \"min\": 3,\n        \"max\": 1647,\n        \"num_unique_values\": 206,\n        \"samples\": [\n          1570,\n          1611,\n          391\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 215,\n        \"samples\": [\n          \"2018-12-14 13:17:41+00:00\",\n          \"2018-11-12 14:03:46+00:00\",\n          \"2020-08-07 06:14:22+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweet Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7254868842568458e+17,\n        \"min\": 6921204594.0,\n        \"max\": 1.4944843105561272e+18,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          1.0735677053057638e+18,\n          1.06198288881451e+18,\n          1.2916186703308347e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 215,\n        \"samples\": [\n          \"[\\u0c0f\\u0c2e\\u0c40 \\u0c38\\u0c47\\u0c24\\u0c41\\u0c30 \\u0c32\\u0c3f\\u0c02\\u0c17\\u0c3e...\\ud83e\\udd23\\ud83e\\udd23\\ud83e\\udd23#bigboss #fun #\\u0c17\\u0c41\\u0c21\\u0c4d \\u0c08\\u0c35\\u0c46\\u0c28\\u0c3f\\u0c02\\u0c17\\u0c4d\\ud83c\\udf06 #\\u0c2b\\u0c28\\u0c4d\\u0c28\\u0c40 #\\u0c08\\u0c35\\u0c46\\u0c28\\u0c3f\\u0c02\\u0c17\\u0c4d] https://t.co/Ddr7WfYn41\",\n          \"\\\"\\\"#\\u0c28\\u0c35\\u0c4d\\u0c35\\u0c41 \\u0c28\\u0c3f \\u0c05\\u0c02\\u0c26\\u0c30\\u0c42 \\u0c2a\\u0c02\\u0c1a\\u0c41\\u0c15\\u0c41\\u0c02\\u0c1f\\u0c3e\\u0c30\\u0c41....   #\\u0c15\\u0c28\\u0c4d\\u0c28\\u0c40\\u0c1f\\u0c3f\\u0c28\\u0c3f \\u0c2e\\u0c28\\u0c38\\u0c4d\\u0c38\\u0c41\\u0c15\\u0c3f \\u0c26\\u0c17\\u0c4d\\u0c17\\u0c30 \\u0c05\\u0c2f\\u0c3f\\u0c28 \\u0c35\\u0c3e\\u0c30\\u0c41 \\u0c2e\\u0c3e\\u0c24\\u0c4d\\u0c30\\u0c2e\\u0c47 \\u0c2a\\u0c02\\u0c1a\\u0c41\\u0c15\\u0c41\\u0c02\\u0c1f\\u0c3e\\u0c30\\u0c41....\",\n          \"\\u0c05\\u0c2f\\u0c28 \\u0c07\\u0c02\\u0c1f\\u0c3f\\u0c15\\u0c3f \\u0c38\\u0c4d\\u0c35\\u0c2f\\u0c02\\u0c17\\u0c3e \\u0c35\\u0c46\\u0c33\\u0c4d\\u0c32\\u0c3f \\u0c2e\\u0c30\\u0c3f \\u0c38\\u0c28\\u0c4d\\u0c2e\\u0c3e\\u0c28\\u0c02 \\u0c1a\\u0c47\\u0c2f\\u0c3f\\u0c02\\u0c1a\\u0c41\\u0c15\\u0c4a\\u0c1a\\u0c4d\\u0c1a\\u0c3e\\u0c30\\u0c41...\\ud83e\\udd23\\ud83e\\udd23\\u0c30\\u0c46\\u0c02\\u0c21\\u0c3f\\u0c1f\\u0c3f\\u0c15\\u0c3f \\u0c2a\\u0c46\\u0c26\\u0c4d\\u0c26 \\u0c24\\u0c47\\u0c21\\u0c3e \\u0c15\\u0c28\\u0c2a\\u0c21\\u0c21\\u0c02 \\u0c32\\u0c47\\u0c26\\u0c41...\\ud83d\\ude46#comedy https://t.co/7EC5UxMHc1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Username\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 101,\n        \"samples\": [\n          \"urs_jafar2\",\n          \"ClickbySBhamidi\",\n          \"Meghana00641006\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Humour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the data"
      ],
      "metadata": {
        "id": "dOk1HlsuWBbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define the preprocessing methods\n",
        "\n",
        "# First preprocessing method\n",
        "def processText(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('((www.[^s]+)|(https?://[^s]+))','',text)\n",
        "    text = re.sub('@[^s]+','',text)\n",
        "    text = re.sub('[s]+', ' ', text)\n",
        "    text = re.sub(r'#([^s]+)', r'1', text)\n",
        "    text = re.sub(r'[.!:?\\-\\'\\\"\\\\\\/]', r'', text)\n",
        "    text = text.strip('\\'\\\"')\n",
        "    return text\n",
        "\n",
        "# Method 1\n",
        "train_data['clean_text'] = train_data['Text'].apply(processText)\n",
        "test_data['clean_text'] = test_data['Text'].apply(processText)\n",
        "\n",
        "# Display the preprocessed data\n",
        "print(\"Training Data:\")\n",
        "print(train_data['clean_text'].head())\n",
        "\n",
        "print(\"\\nTesting Data:\")\n",
        "print(test_data['clean_text'].head())"
      ],
      "metadata": {
        "id": "MKr1BY5lCcz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27151c99-3a5f-4979-c9ee-c435edbbc7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "0                                            ‡∞®‡±á‡∞°‡±Å ‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã ‡∞ú‡±à‡∞≤‡±ç‚Äå‡∞≠‡∞∞‡±ã vhoiv1\n",
            "1    big new  ‡∞è‡∞™‡±Ä‡∞≤‡±ã ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à ‡∞∏‡±Ä‡∞é‡∞Ç ‡∞ú‡∞ó‡∞®‡±ç ‡∞ï‡±Ä‡∞≤‡∞ï ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å ‡∞Ü ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡±Å‡∞Ç‡∞ö‡±á 1\n",
            "2      rahul bajaj ‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§ ‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç‚Äå ‡∞¨‡∞ú‡∞æ‡∞ú‡±ç‚Äå ‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§ triali t 1\n",
            "3                                            ‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å ‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å   1\n",
            "4                                              ‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á 6 ‡∞µ ‡∞¶‡∞ø ‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç1\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Testing Data:\n",
            "0                            ‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç‚Äå‡∞≤‡±ã ‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø ‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á, ‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã ‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á  khnu 1\n",
            "1    ‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞à 22 ‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á ‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø‡∞ï‡∞æ‡∞®‡±Ä1\n",
            "2                                                          ‡∞Æ‡±Ü‡∞ó‡∞æ ‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø ‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç\n",
            "3                                         ‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å ‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ 1\n",
            "4                      ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø ‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞® ‡∞á‡∞∏‡±ç‡∞∞‡±ã ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Å ro cienti t  1\n",
            "Name: clean_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    # Remove special characters, punctuation, and numbers\n",
        "    #text = re.sub(r'[^a-zA-Z‡∞Å-‡∞É‡∞Ö-‡∞ç‡∞é-‡∞è‡∞ê-‡∞ì‡∞î-‡∞®‡∞™-‡∞º‡∞æ-‡±Ñ‡±Ü-‡±à‡±ä-‡±ç]', ' ', text)\n",
        "    text = re.sub('((www.[^s]+)|(https?://[^s]+))','',text)\n",
        "    text = re.sub('@[^s]+','',text)\n",
        "    text = re.sub('[s]+', ' ', text)\n",
        "    text = re.sub(r'#([^s]+)', r'1', text)\n",
        "    text = re.sub(r'[.!:?\\-\\'\\\"\\\\\\/]', r'', text)\n",
        "    text = text.strip('\\'\\\"')\n",
        "    # Convert to lowercase\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "train_data['clean_text'] = train_data['Text'].apply(preprocess_text)\n",
        "\n",
        "# Apply preprocessing to testing data\n",
        "test_data['clean_text'] = test_data['Text'].apply(preprocess_text)\n",
        "\n",
        "# Display the preprocessed data\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTesting Data:\")\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "id": "U62DYU59vz8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccbbf18-16fe-484b-b7f5-ec2faf738001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "   Unnamed: 0  Random_drop_index                   Datetime      Tweet Id  \\\n",
            "0           0                356  2022-02-13 08:13:35+00:00  1.492774e+18   \n",
            "1           1                524  2022-02-10 13:30:07+00:00  1.491766e+18   \n",
            "2           2                395  2022-02-12 12:18:34+00:00  1.492473e+18   \n",
            "3           3               1074  2018-11-01 15:51:26+00:00  1.058024e+18   \n",
            "4           4               1236  2018-02-17 06:45:00+00:00  9.647525e+17   \n",
            "\n",
            "                                                                                                                                                                                                                                              Text  \\\n",
            "0                                                            ‡∞®‡±á‡∞°‡±Å ‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã ‡∞ú‡±à‡∞≤‡±ç‚Äå‡∞≠‡∞∞‡±ãhttps://t.co/Q6CdSvhoiV#JailBaro #Visakhapatnam #protection #Andhrapradesh #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
            "1                                                                                                                                 BIG NEWS: ‡∞è‡∞™‡±Ä‡∞≤‡±ã ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à ‡∞∏‡±Ä‡∞é‡∞Ç ‡∞ú‡∞ó‡∞®‡±ç ‡∞ï‡±Ä‡∞≤‡∞ï ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å.. ‡∞Ü ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡±Å‡∞Ç‡∞ö‡±á.. #news #dailyhunt https://t.co/mlluIriwKd   \n",
            "2  Rahul Bajaj: ‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§ ‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç‚Äå ‡∞¨‡∞ú‡∞æ‡∞ú‡±ç‚Äå ‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§https://t.co/EzX6LrwJ9r#RahulBajaj #BajajGroup #Industrialist #BajajTwoWheeler #BajajThreeWheeler #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
            "3                                                       ‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å ‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å @Ileana_Official#tollywoodactress #hot #funny #memes #telugu #hyderabad #telengana #birthday #happybirthday #girls #november #IleanaDCruz https://t.co/ZbCgegQo6o   \n",
            "4                                                                                                                                                                                ‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á 6 ‡∞µ ‡∞¶‡∞ø ‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç..!#Funny: üòõ üòõ üòõ https://t.co/uiKN2aPJ26   \n",
            "\n",
            "         Username  Humour  \\\n",
            "0    hmtvnewslive       0   \n",
            "1       DH_Telugu       0   \n",
            "2    hmtvnewslive       0   \n",
            "3   CoconutComedy       0   \n",
            "4  fbtelugupeople       0   \n",
            "\n",
            "                                                                          clean_text  \n",
            "0                                                  [‡∞®‡±á‡∞°‡±Å, ‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã, ‡∞ú‡±à‡∞≤‡±ç‚Äå‡∞≠‡∞∞‡±ã, vhoiv1]  \n",
            "1  [big, new, ‡∞è‡∞™‡±Ä‡∞≤‡±ã, ‡∞ï‡±ä‡∞§‡±ç‡∞§, ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à, ‡∞∏‡±Ä‡∞é‡∞Ç, ‡∞ú‡∞ó‡∞®‡±ç, ‡∞ï‡±Ä‡∞≤‡∞ï, ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å, ‡∞Ü, ‡∞∞‡±ã‡∞ú‡±Å, ‡∞®‡±Å‡∞Ç‡∞ö‡±á, 1]  \n",
            "2      [rahul, bajaj, ‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú, ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§, ‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç‚Äå, ‡∞¨‡∞ú‡∞æ‡∞ú‡±ç‚Äå, ‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§, triali, t, 1]  \n",
            "3                                                     [‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å, ‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å, 1]  \n",
            "4                                                   [‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á, 6, ‡∞µ, ‡∞¶‡∞ø, ‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç1]  \n",
            "\n",
            "Testing Data:\n",
            "   Unnamed: 0  Random_drop_index                   Datetime      Tweet Id  \\\n",
            "0           0                273  2022-02-14 14:35:00+00:00  1.493232e+18   \n",
            "1           1               1223  2018-02-24 13:45:24+00:00  9.673950e+17   \n",
            "2           2               1554  2016-05-30 06:40:33+00:00  7.371718e+17   \n",
            "3           3                526  2022-02-10 11:40:06+00:00  1.491739e+18   \n",
            "4           4                405  2022-02-12 10:11:41+00:00  1.492441e+18   \n",
            "\n",
            "                                                                                                                                                                                                                            Text  \\\n",
            "0  ‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç‚Äå‡∞≤‡±ã ‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø ‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á, ‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã ‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á https://t.co/qZpcgskhNu #assembly #poll #campaign #CaptAmarinderSingh #NarendraModi #NDA #YogiAdityanath #Telugu #NEWS #Telangana #AndhraPradesh #NewsUpdates #Newsfile   \n",
            "1                                                                                         ‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞à 22 ‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á ‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å..!‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø..‡∞ï‡∞æ‡∞®‡±Ä.!#Funny: :-P :-P :-P https://t.co/oNQKqUveMa   \n",
            "2                                                                                                                                                              ‡∞Æ‡±Ü‡∞ó‡∞æ ‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø ‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç..!https://t.co/G2BGZgZOr9 #comedy   \n",
            "3                                                                                                                                  ‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å ‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç.. ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ..!! #news #dailyhunt https://t.co/2Srp8tHAz1   \n",
            "4                    ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø ‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞® ‡∞á‡∞∏‡±ç‡∞∞‡±ã ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Åhttps://t.co/00WaqqXcJ7#ISROscientists #Tirumala #PSLVC52 #Rocket #hmtvnews #hmtvlivenews #todaynews #todaylivenews #latestnews #livenews #news #tvnews   \n",
            "\n",
            "         Username  Humour  \\\n",
            "0      NijamToday       0   \n",
            "1  fbtelugupeople       0   \n",
            "2   Kalpanapriyap       0   \n",
            "3       DH_Telugu       0   \n",
            "4    hmtvnewslive       0   \n",
            "\n",
            "                                                                                        clean_text  \n",
            "0                          [‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç‚Äå‡∞≤‡±ã, ‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø, ‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á, ,, ‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã, ‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø, ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á, khnu, 1]  \n",
            "1  [‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à, ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®, ‡∞à, 22, ‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç, ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á, ‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á, ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø‡∞ï‡∞æ‡∞®‡±Ä1]  \n",
            "2                                                             [‡∞Æ‡±Ü‡∞ó‡∞æ, ‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã, ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø, ‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç]  \n",
            "3                                         [‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø, ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å, ‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç, ‡∞é‡∞≤‡∞æ, ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã, ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ, 1]  \n",
            "4                     [‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤, ‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø, ‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®, ‡∞á‡∞∏‡±ç‡∞∞‡±ã, ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Å, ro, cienti, t, 1]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary for the dataset"
      ],
      "metadata": {
        "id": "NErVjQW9WFBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all unique tokens from the data\n",
        "vocabulary = set()\n",
        "for text in train_data['clean_text']:\n",
        "    vocabulary.update(set(text))\n",
        "\n",
        "# Calculate the vocabulary size\n",
        "vocabulary_size = len(vocabulary)\n",
        "\n",
        "# Print the vocabulary and its size\n",
        "print(\"Vocabulary Size:\", vocabulary_size)\n",
        "print(\"\\nVocabulary:\")\n",
        "print(vocabulary)"
      ],
      "metadata": {
        "id": "R4GcpvD9WNIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# n - grams"
      ],
      "metadata": {
        "id": "sXpxlNAQWJGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Function to generate n-grams\n",
        "def generate_ngrams(tokens, n):\n",
        "    return list(ngrams(tokens, n))\n",
        "\n",
        "# Define the value of n for n-grams (e.g., unigrams (n=1), bigrams (n=2), trigrams (n=3))\n",
        "n = 2\n",
        "\n",
        "# Function to compute and display bigram probabilities\n",
        "def compute_and_display_bigram_probabilities(text):\n",
        "    # Generate n-grams\n",
        "    ngrams_list = generate_ngrams(text, n)\n",
        "\n",
        "    # Count occurrences of each n-gram\n",
        "    ngram_counts = Counter(ngrams_list)\n",
        "\n",
        "    # Calculate probabilities\n",
        "    total_count = sum(ngram_counts.values())\n",
        "    bigram_prob = {bigram: count / total_count for bigram, count in ngram_counts.items()}\n",
        "\n",
        "    # Convert bigram probabilities dictionary into a list of tuples\n",
        "    bigram_table = [(bigram, probability) for bigram, probability in bigram_prob.items()]\n",
        "\n",
        "    # Define table headers\n",
        "    headers_bigram = [\"Bigram\", \"Bigram Probability\"]\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\nBigram Probabilities:\")\n",
        "    print(tabulate(bigram_table, headers=headers_bigram, tablefmt=\"pretty\"))\n",
        "\n",
        "# Example usage:\n",
        "print(\"Sample N-grams from Training Data:\")\n",
        "for i in range(5):\n",
        "    compute_and_display_bigram_probabilities(train_data['clean_text'][i])\n",
        "\n",
        "print(\"\\nSample N-grams from Testing Data:\")\n",
        "for i in range(5):\n",
        "    compute_and_display_bigram_probabilities(test_data['clean_text'][i])"
      ],
      "metadata": {
        "id": "AAlWGJcYwF7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b888fe56-64c1-4642-8f2f-8769d0ca1b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample N-grams from Training Data:\n",
            "\n",
            "Bigram Probabilities:\n",
            "+--------------------------+--------------------+\n",
            "|          Bigram          | Bigram Probability |\n",
            "+--------------------------+--------------------+\n",
            "|      ('‡∞®‡±á‡∞°‡±Å', '‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã')      | 0.3333333333333333 |\n",
            "|  ('‡∞µ‡∞ø‡∞∂‡∞æ‡∞ñ‡∞≤‡±ã', '‡∞ú‡±à‡∞≤‡±ç\\u200c‡∞≠‡∞∞‡±ã')  | 0.3333333333333333 |\n",
            "| ('‡∞ú‡±à‡∞≤‡±ç\\u200c‡∞≠‡∞∞‡±ã', 'vhoiv1') | 0.3333333333333333 |\n",
            "+--------------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+------------------+---------------------+\n",
            "|      Bigram      | Bigram Probability  |\n",
            "+------------------+---------------------+\n",
            "|  ('big', 'new')  | 0.08333333333333333 |\n",
            "|  ('new', '‡∞è‡∞™‡±Ä‡∞≤‡±ã')  | 0.08333333333333333 |\n",
            "|  ('‡∞è‡∞™‡±Ä‡∞≤‡±ã', '‡∞ï‡±ä‡∞§‡±ç‡∞§')  | 0.08333333333333333 |\n",
            "| ('‡∞ï‡±ä‡∞§‡±ç‡∞§', '‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à') | 0.08333333333333333 |\n",
            "| ('‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡∞™‡±à', '‡∞∏‡±Ä‡∞é‡∞Ç')  | 0.08333333333333333 |\n",
            "|  ('‡∞∏‡±Ä‡∞é‡∞Ç', '‡∞ú‡∞ó‡∞®‡±ç')   | 0.08333333333333333 |\n",
            "|  ('‡∞ú‡∞ó‡∞®‡±ç', '‡∞ï‡±Ä‡∞≤‡∞ï')  | 0.08333333333333333 |\n",
            "| ('‡∞ï‡±Ä‡∞≤‡∞ï', '‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å')  | 0.08333333333333333 |\n",
            "|  ('‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å', '‡∞Ü')   | 0.08333333333333333 |\n",
            "|   ('‡∞Ü', '‡∞∞‡±ã‡∞ú‡±Å')    | 0.08333333333333333 |\n",
            "|   ('‡∞∞‡±ã‡∞ú‡±Å', '‡∞®‡±Å‡∞Ç‡∞ö‡±á')   | 0.08333333333333333 |\n",
            "|   ('‡∞®‡±Å‡∞Ç‡∞ö‡±á', '1')    | 0.08333333333333333 |\n",
            "+------------------+---------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+----------------------------+--------------------+\n",
            "|           Bigram           | Bigram Probability |\n",
            "+----------------------------+--------------------+\n",
            "|     ('rahul', 'bajaj')     | 0.1111111111111111 |\n",
            "|     ('bajaj', '‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú')      | 0.1111111111111111 |\n",
            "|    ('‡∞¶‡∞ø‡∞ó‡±ç‡∞ó‡∞ú', '‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§')     | 0.1111111111111111 |\n",
            "|  ('‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§', '‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç\\u200c')  | 0.1111111111111111 |\n",
            "| ('‡∞∞‡∞æ‡∞π‡±Å‡∞≤‡±ç\\u200c', '‡∞¨‡∞ú‡∞æ‡∞ú‡±ç\\u200c') | 0.1111111111111111 |\n",
            "|   ('‡∞¨‡∞ú‡∞æ‡∞ú‡±ç\\u200c', '‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§')   | 0.1111111111111111 |\n",
            "|    ('‡∞ï‡∞®‡±ç‡∞®‡±Å‡∞Æ‡±Ç‡∞§', 'triali')     | 0.1111111111111111 |\n",
            "|      ('triali', 't')       | 0.1111111111111111 |\n",
            "|         ('t', '1')         | 0.1111111111111111 |\n",
            "+----------------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+----------------------+--------------------+\n",
            "|        Bigram        | Bigram Probability |\n",
            "+----------------------+--------------------+\n",
            "| ('‡∞™‡±Å‡∞ü‡±ç‡∞ü‡∞ø‡∞®‡∞∞‡±ã‡∞ú‡±Å', '‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å') |        0.5         |\n",
            "|   ('‡∞∂‡±Å‡∞≠‡∞æ‡∞ï‡∞æ‡∞Ç‡∞ï‡±ç‡∞∑‡∞≤‡±Å', '1')    |        0.5         |\n",
            "+----------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+-----------------+--------------------+\n",
            "|     Bigram      | Bigram Probability |\n",
            "+-----------------+--------------------+\n",
            "| ('‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡∞Ç‡∞ü‡±á', '6') |        0.25        |\n",
            "|   ('6', '‡∞µ')    |        0.25        |\n",
            "|   ('‡∞µ', '‡∞¶‡∞ø')    |        0.25        |\n",
            "|  ('‡∞¶‡∞ø', '‡∞π‡±à‡∞≤‡±à‡∞ü‡±ç1')  |        0.25        |\n",
            "+-----------------+--------------------+\n",
            "\n",
            "Sample N-grams from Testing Data:\n",
            "\n",
            "Bigram Probabilities:\n",
            "+-------------------------+--------------------+\n",
            "|         Bigram          | Bigram Probability |\n",
            "+-------------------------+--------------------+\n",
            "| ('‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç\\u200c‡∞≤‡±ã', '‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø') |       0.125        |\n",
            "|    ('‡∞∞‡∞æ‡∞®‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø', '‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á')    |       0.125        |\n",
            "|      ('‡∞é‡∞®‡±ç‡∞°‡±Ä‡∞Ø‡±á', ',')      |       0.125        |\n",
            "|      (',', '‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã')       |       0.125        |\n",
            "|     ('‡∞Ø‡±Å‡∞™‡∞ø‡∞≤‡±ã', '‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø')      |       0.125        |\n",
            "|    ('‡∞¨‡∞ø‡∞ú‡±Ü‡∞™‡∞ø', '‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á')    |       0.125        |\n",
            "|   ('‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Æ‡±á', 'khnu')    |       0.125        |\n",
            "|      ('khnu', '1')      |       0.125        |\n",
            "+-------------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+---------------------------+--------------------+\n",
            "|          Bigram           | Bigram Probability |\n",
            "+---------------------------+--------------------+\n",
            "|     ('‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å‡∞™‡±à', '‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®')     |       0.125        |\n",
            "|      ('‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®', '‡∞à')       |       0.125        |\n",
            "|        ('‡∞à', '22')        |       0.125        |\n",
            "|       ('22', '‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç')       |       0.125        |\n",
            "|      ('‡∞Ø‡∞æ‡∞°‡±ç‡∞∏‡±ç', '‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á')       |       0.125        |\n",
            "| ('‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á', '‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å') |       0.125        |\n",
            "| ('‡∞®‡∞µ‡±ç‡∞µ‡∞æ‡∞™‡±Å‡∞ï‡±ã‡∞≤‡±á‡∞∞‡±Å‡∞Ö‡∞Ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å', '‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á') |       0.125        |\n",
            "|    ('‡∞¨‡∞æ‡∞ó‡∞æ‡∞®‡±á', '‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø‡∞ï‡∞æ‡∞®‡±Ä1')     |       0.125        |\n",
            "+---------------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+--------------------+--------------------+\n",
            "|       Bigram       | Bigram Probability |\n",
            "+--------------------+--------------------+\n",
            "|   ('‡∞Æ‡±Ü‡∞ó‡∞æ', '‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã')    | 0.3333333333333333 |\n",
            "| ('‡∞π‡±Ä‡∞∞‡±ã‡∞§‡±ã', '‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø')  | 0.3333333333333333 |\n",
            "| ('‡∞∏‡∞æ‡∞Ø‡∞ø‡∞™‡∞≤‡±ç‡∞≤‡∞µ‡∞ø', '‡∞∞‡±ä‡∞Æ‡∞æ‡∞®‡±ç‡∞∏‡±ç') | 0.3333333333333333 |\n",
            "+--------------------+--------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+---------------------+---------------------+\n",
            "|       Bigram        | Bigram Probability  |\n",
            "+---------------------+---------------------+\n",
            "| ('‡∞∏‡∞ö‡∞ø‡∞µ‡∞æ‡∞≤‡∞Ø', '‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å') | 0.16666666666666666 |\n",
            "| ('‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡±Å‡∞≤‡∞ï‡±Å', '‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç')  | 0.16666666666666666 |\n",
            "|   ('‡∞Ø‡±Ç‡∞®‡∞ø‡∞´‡∞æ‡∞Æ‡±ç', '‡∞é‡∞≤‡∞æ')    | 0.16666666666666666 |\n",
            "|    ('‡∞é‡∞≤‡∞æ', '‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã')    | 0.16666666666666666 |\n",
            "|   ('‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡±ã', '‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ')    | 0.16666666666666666 |\n",
            "|    ('‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡∞æ', '1')     | 0.16666666666666666 |\n",
            "+---------------------+---------------------+\n",
            "\n",
            "Bigram Probabilities:\n",
            "+----------------------+--------------------+\n",
            "|        Bigram        | Bigram Probability |\n",
            "+----------------------+--------------------+\n",
            "|  ('‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤', '‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø')   |       0.125        |\n",
            "| ('‡∞∂‡±ç‡∞∞‡±Ä‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø', '‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®') |       0.125        |\n",
            "|  ('‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®', '‡∞á‡∞∏‡±ç‡∞∞‡±ã')  |       0.125        |\n",
            "| ('‡∞á‡∞∏‡±ç‡∞∞‡±ã', '‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Å')  |       0.125        |\n",
            "|  ('‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞≤‡±Å', 'ro')  |       0.125        |\n",
            "|   ('ro', 'cienti')   |       0.125        |\n",
            "|   ('cienti', 't')    |       0.125        |\n",
            "|      ('t', '1')      |       0.125        |\n",
            "+----------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOW"
      ],
      "metadata": {
        "id": "WPtDVLpvWNKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(train_data['clean_text'].apply(lambda x: ' '.join(x)))\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_bow = vectorizer.transform(test_data['clean_text'].apply(lambda x: ' '.join(x)))\n",
        "\n",
        "# Print the shape of the BoW matrices\n",
        "print(\"Shape of X_train_bow:\", X_train_bow.shape)\n",
        "print(\"Shape of X_test_bow:\", X_test_bow.shape)"
      ],
      "metadata": {
        "id": "OAVq-78fwRyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039fab7c-703e-41ef-cadc-3baf6c54f7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (862, 1130)\n",
            "Shape of X_test_bow: (216, 1130)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define a dummy neural network architecture\n",
        "input_layer = Input(shape=(X_train_bow.shape[1],))\n",
        "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using Bag of Words (BoW) features\n",
        "model.fit(X_train_bow.toarray(), train_data['Humour'], epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Get the hidden representation of the data\n",
        "get_hidden_representation = tf.keras.backend.function([model.layers[0].input], [model.layers[1].output])\n",
        "hidden_representations = get_hidden_representation([X_train_bow.toarray()])[0]\n",
        "\n",
        "# Compute Neural Tangent Kernel (NTK)\n",
        "ntk_matrix = np.dot(hidden_representations, np.transpose(hidden_representations))\n",
        "\n",
        "\n",
        "# Print the shape of the NTK matrix\n",
        "print(\"Shape of NTK matrix:\", ntk_matrix.shape)\n"
      ],
      "metadata": {
        "id": "aM39fkDFwX9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e654f22-e0c2-46c2-d6a1-c22aaf1c9bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of NTK matrix: (862, 862)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_bow, train_data['Humour'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize the machine learning model (e.g., SVM)\n",
        "model = SVC()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "5IQ0R2IywZ4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1ea953-90a0-4ce0-9c01-1c689bd13005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6184971098265896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "kZSkHuuXwc_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5719ef71-1306-4f4d-bcf5-c401363a5978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6184971098265896\n",
            "Precision: 0.6018518518518519\n",
            "Recall: 0.7386363636363636\n",
            "F1-score: 0.663265306122449\n",
            "ROC-AUC Score: 0.6163770053475937\n",
            "Confusion Matrix:\n",
            "[[42 43]\n",
            " [23 65]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert lists of tokens into strings\n",
        "train_data['clean_text_str'] = train_data['clean_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# TF-IDF Feature Extraction\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_data['clean_text_str'])\n",
        "\n",
        "# Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, train_data['Humour'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Return TF-IDF features\n",
        "X_train_tfidf, X_test_tfidf"
      ],
      "metadata": {
        "id": "3wYwxl14wgC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e35133e-d601-452c-be1f-c844a211a6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<689x1130 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 3236 stored elements in Compressed Sparse Row format>,\n",
              " <173x1130 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 741 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC  # Example: Using Support Vector Classifier (SVC)\n",
        "\n",
        "# Initialize the classifier (you can use any classifier of your choice)\n",
        "classifier = SVC()\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"ROC-AUC:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "6VbKRk1kwigg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d036030d-4c2f-4f50-d8ea-976a871ae5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6416184971098265\n",
            "Precision: 0.6382978723404256\n",
            "Recall: 0.6818181818181818\n",
            "F1-score: 0.6593406593406593\n",
            "ROC-AUC: 0.6409090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT USAGE**"
      ],
      "metadata": {
        "id": "ZPA3N8P6wpdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_colwidth',None)   #this displays the dataframe in full width\n",
        "import collections\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "aco5eu75wlLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model =  \"distilbert-base-multilingual-cased\"\n",
        "#pretrained_model = \"xlm-roberta-base\"\n",
        "#pretrained_model = \"bert-base-multilingual-cased\""
      ],
      "metadata": {
        "id": "jjinzw6Nwvs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "mE1eWfP9w4KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9496d32-3792-4105-cdaa-82e7c93ab20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"./final_train.csv\")\n",
        "df_test = pd.read_csv(\"./final_test.csv\")"
      ],
      "metadata": {
        "id": "OzgUma3-xP-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, tuples):\n",
        "\n",
        "      self.tuples = tuples\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tuples)\n",
        "\n",
        "    def tokenize_function(self, text):\n",
        "        return self.tokenizer(text, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      text, label = self.tuples[ idx ][0], self.tuples[ idx ][1]\n",
        "\n",
        "      text = self.tokenize_function( text )\n",
        "\n",
        "      label = [ 0, 1 ] if label == 1 else [1,0]\n",
        "      text['labels'] = torch.Tensor( label )\n",
        "\n",
        "      return text"
      ],
      "metadata": {
        "id": "oKgV8fiYxdFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = df['Humour'].to_list()\n",
        "        self.texts = [tokenizer(text,\n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['Text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "oZZQk5whxiL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4a382e-a519-440c-fda1-4a14c8817e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel, AutoModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(pretrained_model) # AutoModel.from_pretrained(pretrained_model) # BertModel.from_pretrained(pretrained_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "nUtYRKCdxpDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "\n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "\n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "EPOCHS = 10\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "\n",
        "df_train.sample(frac=1)\n",
        "train(model, df_train, df_test, LR, EPOCHS)"
      ],
      "metadata": {
        "id": "CrIvqRirxruJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f6aa68c3-8830-47dd-be69-3bae9e945101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 19%|‚ñà‚ñâ        | 84/431 [20:44<1:25:41, 14.82s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3e93691260d9>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-3e93691260d9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2947eed86bb4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_id, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdropout_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlinear_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         )\n\u001b[0;32m--> 988\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         )\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    pred, tlabels = [], []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              # pred.append( output.argmax(dim=1) )\n",
        "\n",
        "              pred.extend( output.argmax(dim=1).tolist() )\n",
        "              tlabels.extend( test_label.tolist() )\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "\n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    print(\"Test precision, recall and f1-score: \", precision_recall_fscore_support( tlabels, pred, average=\"macro\" ) )\n",
        "    print(\"Test precision, recall and f1-score label-wise: \", precision_recall_fscore_support( tlabels, pred ) )\n",
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "NfAi_xDEx4Ft"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}